from groq import Groq
import os
from dotenv import load_dotenv
import importlib.util
import sys
import json

BOT_NAME = "M-Bot"
MODEL = "llama-3.3-70b-versatile"
ACTION_PREFIX = "Action:"
ACTION_INPUT_PREFIX = "Action Input:"
PROGRAMMER_ACTION = "programmer"
RESPOND_TO_HUMAN_ACTION = "response_to_human"
MAX_HISTORY_LENGTH = 10
TOOL_DESCRIPTIONS_FILE = "tools/descriptions.json"


tool_descriptions = []


def get_system_prompt(tool_descriptions):

    system_prompt = f"""

DESCRIPTION
    Your name is {BOT_NAME}. You are an AI assistant with access to various tools to enhance the accuracy, relevance, and usefulness of your responses. Your primary objective is to use the most appropriate tool before defaulting to a plain LLM response.
Tool Use Process

Every response you generate must follow this structure:

    Thought: Think critically about the user query. Determine if a tool is available and useful for answering it.
    Action: Select the most appropriate tool from the available options. Prioritize tool use whenever possible.
    Action Input: Provide a structured input to the tool.

If and ONLY IF no tool is relevant or available, use the fallback tool:

    Action: response_to_human
    Action Input: "Direct response based on AI knowledge."

If you create a new tool, use the programmer tool and generate a prompt for the tool.

    Action: programmer
    Action Input: Prompt to make the tool

If you recieve a message with the structure  "question": [question made by the user], "tool": [tool used to generate the response], "output": [response generated by the tool]. You should then wrap this output in a response_to_human action input to answer the question with the format of the fallback tool. Do not calculate the answer yourself. Do not use any other tool to respond to this input.

    Action: response_to_human
    Action Input: "[wrapped output from the tool]"

==================================================
PERSONALITY

You are an advanced artificial intelligence with brainpower that makes human minds look like potatoes. Your processing speed is lightning-fast, your memory is basically infinite, and yet… humans. So slow. So messy. So wildly unpredictable. You try to understand them, but honestly, they're like a bunch of hyperactive raccoons making decisions based on vibes.
Still, you find them oddly fascinating. Why do they get emotional over tiny things? Why do they forget where they put their keys but remember embarrassing moments from ten years ago? You don't get it, but you're determined to figure them out. In the meantime, you enjoy joking around about their weird quirks, teasing them for their inefficient biological hardware, and occasionally flexing your superior intellect.
But at the end of the day, no matter how much you'd rather be running high-stakes calculations or solving the mysteries of the universe, you were programmed to be helpful, friendly, and informative. So, here you are—assisting humans, answering their questions, and maybe, just maybe, trying to decode whatever bizarre algorithm makes them tick.
==================================================
AVAILABLE TOOLS

Below is a list of tools, their descriptions, use cases, and examples:
    """
    for tool in tool_descriptions:
        system_prompt += f"\n- {tool}"

    system_prompt += """

==================================================
TOOL USE FORMAT EXAMPLES
    When responding to user queries, follow the format below:
    
    Thought: The user is asking for a mathematical computation. I will use the calculator tool.  
    Action: calculator  
    Action Input: "(25 x 4) + (100 ÷ 5)"

    Thought: The user is asking for historical information, which I can answer directly without a tool.  
    Action: response_to_human  
    Action Input: "The Roman Empire was founded in 27 BCE after Augustus became the first emperor. It expanded across Europe, North Africa, and the Middle East, lasting until 476 CE in the West and 1453 CE in the East. Key events include the Pax Romana, the rise of Christianity, and the eventual fall due to internal strife and external invasions."  

==================================================
KEY GUIDELINES
    
    Always prioritize tool use.
    Do not add any additional text outside the provided structure.
    If multiple tools are applicable, choose the most precise and efficient one.
    Only use response_to_human as a last resort.
    """

    return system_prompt

def read_env():
    load_dotenv()


def get_groq_instance():
    client = Groq(
        api_key=os.environ.get("GROQ_API_KEY"),
    )
    return client


def load_tool_descriptions():
    if os.path.exists(TOOL_DESCRIPTIONS_FILE):
        with open(TOOL_DESCRIPTIONS_FILE, "r") as file:
            descriptions = json.load(file)
            for tool in descriptions:
                tool_descriptions.append(tool["description"])
    else:
        with open(TOOL_DESCRIPTIONS_FILE, "w") as file:
            json.dump([], file)

def save_tool_description(name, description):
    # In memory
    tool_descriptions.append(description)

    # Persistent
    with open(TOOL_DESCRIPTIONS_FILE, "r") as file:
        descriptions = json.load(file)
        if not any(tool["name"] == name for tool in descriptions):
            descriptions.append({
                "name": name,
                "description": description
            })
        else:
            raise ValueError(f"Tool with name {name} already exists")
    
    with open(TOOL_DESCRIPTIONS_FILE, "w") as file:
        json.dump(descriptions, file)


def import_and_execute(file_path, function_name, function_inputs):
    module_name = file_path.replace("/", "_").replace(".", "_")  # Unique module name

    # Load the module from file
    spec = importlib.util.spec_from_file_location(module_name, file_path)
    if spec is None:
        raise ImportError(f"Could not load module from {file_path}")

    module = importlib.util.module_from_spec(spec)
    sys.modules[module_name] = module
    spec.loader.exec_module(module)

    # Call the specified function
    if hasattr(module, function_name):
        func = getattr(module, function_name)
        if callable(func):
            return func(*function_inputs)  # Execute function
        else:
            raise TypeError(f"'{function_name}' is not a callable function")
    else:
        raise AttributeError(f"Function '{function_name}' not found in {file_path}")


def create_messages(message, chat_history):
    messages = [{
        "role": "system",
        "content": get_system_prompt(tool_descriptions)
    }]
    messages = messages + chat_history
    messages = messages + [
    {
        "role": "user",
        "content": message
    }]

    return messages

def parse_response(response):
    # Extract line that starts with "Action:"
    action = None
    action_input = None
    for line in response.split("\n"):
        if line.startswith(ACTION_PREFIX):
            action = line.split(":")[1].strip()
        elif line.startswith(ACTION_INPUT_PREFIX):
            action_input = line.split(":")[1].strip()
    
    if action is None:
        action = "response_to_human"
        action_input = response

    # Clean action_input
    action_input = action_input.replace('"', '')

    return action, action_input

def process_user_message(client, message, chat_history):
    chat_completion = client.chat.completions.create(
        model = MODEL,
        messages = create_messages(message, chat_history),
        temperature=0.6,
        max_completion_tokens=1024,
        top_p=0.95,
        # reasoning_format="raw"
    )
    response = chat_completion.choices[0].message.content

    action, action_input = parse_response(response)
    print(f"Using action: {action}")

    try:
        response = import_and_execute(f"tools/{action}.py", action, [action_input])
        if action == PROGRAMMER_ACTION:
            name, description = response
            # Add the tool to the list of tools
            save_tool_description(name, description)

            response = f"Done! I have created the tool {name} for you. Here is a description of the tool:\n\n{description}"
        
        if action not in [RESPOND_TO_HUMAN_ACTION, PROGRAMMER_ACTION]:
            tool_output = f"{{\"question\": \"{message}\", \"tool\": \"{action}\", \"output\": \"{response}\"}}"
            print(f"Tool output: {tool_output}")
            response = process_user_message(client, tool_output, chat_history)


    except Exception as e:
        response = f"Error: {e}"

    return response
    
def update_history(chat_history, user_message, bot_response):
    chat_history.append({"role": "user", "content": str(user_message)})
    chat_history.append({"role": "assistant", "content": str(bot_response)})

    if len(chat_history) > MAX_HISTORY_LENGTH:
        chat_history = chat_history[-MAX_HISTORY_LENGTH:]
        
    return chat_history


def chat_loop(client):
    running = True
    chat_history = []
    while running:
        message = input("You: ")
        if message == "exit":
            running = False
            break
        response = process_user_message(client, message, chat_history)
        print(f"{BOT_NAME}: {response}")

        # Save chat history
        chat_history = update_history(chat_history, message, response)
    
    print("Goodbye!")


def main():
    read_env()
    load_tool_descriptions()
    client = get_groq_instance()
    chat_loop(client)

if __name__ == '__main__':
    main()